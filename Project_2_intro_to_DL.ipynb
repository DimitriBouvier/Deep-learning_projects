{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-bn3HMh4-5w",
        "outputId": "f8eac254-ce25-4ce4-dfdd-8ed98715b4fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31 entries, 0 to 30\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    31 non-null     object \n",
            " 1   tavg    28 non-null     float64\n",
            " 2   tmin    28 non-null     float64\n",
            " 3   tmax    28 non-null     float64\n",
            " 4   prcp    0 non-null      float64\n",
            " 5   snow    0 non-null      float64\n",
            " 6   wdir    1 non-null      float64\n",
            " 7   wspd    27 non-null     float64\n",
            " 8   wpgt    0 non-null      float64\n",
            " 9   pres    27 non-null     float64\n",
            " 10  tsun    0 non-null      float64\n",
            "dtypes: float64(10), object(1)\n",
            "memory usage: 2.8+ KB\n",
            "None\n",
            "         date  tavg  tmin  tmax  prcp  snow  wdir  wspd  wpgt    pres  tsun\n",
            "0  2020-01-01   3.6   1.7   5.0   NaN   NaN   NaN  17.3   NaN  1008.2   NaN\n",
            "1  2020-01-02   4.7   0.6   8.9   NaN   NaN   NaN  12.4   NaN  1013.9   NaN\n",
            "2  2020-01-03   7.6   6.7   8.3   NaN   NaN   NaN   8.4   NaN  1010.2   NaN\n",
            "3  2020-01-04   8.2   6.7   9.4   NaN   NaN   NaN   5.7   NaN  1003.7   NaN\n",
            "4  2020-01-05   4.6   2.8   7.2   NaN   NaN   NaN   8.2   NaN  1010.1   NaN\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd,sys, numpy as np\n",
        "from datetime import datetime,timedelta\n",
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')\n",
        "df_temp = pd.read_excel((r'/content/drive/MyDrive/Project 2 intro to DL DFs/NYC temp.xlsx'))\n",
        "df_temp['date'] = df_temp['date'].astype(str)\n",
        "df_temp['date'] = pd.Series(map(lambda x: datetime.strptime(str(x),'%Y-%m-%d'),df_temp['date'])).dt.date\n",
        "print(df_temp.info())\n",
        "print(df_temp.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihg_eUlw4GPi",
        "outputId": "50f7e760-9888-4769-b127-6dd9ba541305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date    0\n",
            "tavg    0\n",
            "tmin    0\n",
            "tmax    0\n",
            "wspd    0\n",
            "pres    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#keeping only columns with at least 27 non-null values\n",
        "df_temp = df_temp[['date','tavg','tmin','tmax','wspd','pres']]\n",
        "#filling numerical series with mean of said series\n",
        "for col in df_temp:\n",
        "  if df_temp[col].dtype == 'float64':\n",
        "    df_temp[col].fillna(np.mean(df_temp[col]),inplace=True)\n",
        "print(df_temp.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUii850X9ufg",
        "outputId": "773ee07b-899c-4a8a-d688-23e550490c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1000000 entries, 1432517 to 4443048\n",
            "Data columns (total 19 columns):\n",
            " #   Column                 Non-Null Count    Dtype         \n",
            "---  ------                 --------------    -----         \n",
            " 0   VendorID               1000000 non-null  int64         \n",
            " 1   tpep_pickup_datetime   1000000 non-null  datetime64[ns]\n",
            " 2   tpep_dropoff_datetime  1000000 non-null  datetime64[ns]\n",
            " 3   passenger_count        989787 non-null   float64       \n",
            " 4   trip_distance          1000000 non-null  float64       \n",
            " 5   RatecodeID             989787 non-null   float64       \n",
            " 6   store_and_fwd_flag     989787 non-null   float64       \n",
            " 7   PULocationID           1000000 non-null  int64         \n",
            " 8   DOLocationID           1000000 non-null  int64         \n",
            " 9   payment_type           1000000 non-null  int64         \n",
            " 10  fare_amount            1000000 non-null  float64       \n",
            " 11  extra                  1000000 non-null  float64       \n",
            " 12  mta_tax                1000000 non-null  float64       \n",
            " 13  tip_amount             1000000 non-null  float64       \n",
            " 14  tolls_amount           1000000 non-null  float64       \n",
            " 15  improvement_surcharge  1000000 non-null  float64       \n",
            " 16  total_amount           1000000 non-null  float64       \n",
            " 17  congestion_surcharge   989787 non-null   float64       \n",
            " 18  airport_fee            0 non-null        object        \n",
            "dtypes: datetime64[ns](2), float64(12), int64(4), object(1)\n",
            "memory usage: 152.6+ MB\n",
            "None\n",
            "VendorID                       0\n",
            "tpep_pickup_datetime           0\n",
            "tpep_dropoff_datetime          0\n",
            "passenger_count            10213\n",
            "trip_distance                  0\n",
            "RatecodeID                 10213\n",
            "store_and_fwd_flag         10213\n",
            "PULocationID                   0\n",
            "DOLocationID                   0\n",
            "payment_type                   0\n",
            "fare_amount                    0\n",
            "extra                          0\n",
            "mta_tax                        0\n",
            "tip_amount                     0\n",
            "tolls_amount                   0\n",
            "improvement_surcharge          0\n",
            "total_amount                   0\n",
            "congestion_surcharge       10213\n",
            "airport_fee              1000000\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# pd.options.display.max_info_rows = 4000000\n",
        "df_taxi = pd.read_parquet((r'/content/drive/MyDrive/Project 2 intro to DL DFs/yellow_tripdata_2020-01.parquet')).sample(n=1000000)#.iloc[:200000,:]\n",
        "df_taxi['store_and_fwd_flag'] = df_taxi['store_and_fwd_flag'].map({'Y': 1, 'N': 0})\n",
        "print(df_taxi.info())\n",
        "print(df_taxi.isnull().sum())\n",
        "# print(df_taxi.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho0bdWnQ9uia"
      },
      "outputs": [],
      "source": [
        "df_taxi.drop(columns='airport_fee',inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R4cKG1REEJf"
      },
      "source": [
        "# Merging both DFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6jy9OcA9ulW"
      },
      "outputs": [],
      "source": [
        "df_taxi['date'] = df_taxi['tpep_pickup_datetime'].dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKFYtNQF9un_",
        "outputId": "50d23aaa-d368-43c7-deb2-b75b1cef034c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   VendorID  passenger_count  trip_distance  RatecodeID  store_and_fwd_flag  \\\n",
            "0         2              2.0           2.22         1.0                 0.0   \n",
            "1         1              2.0           4.80         1.0                 0.0   \n",
            "2         2              1.0           1.18         1.0                 0.0   \n",
            "3         2              1.0           1.31         1.0                 0.0   \n",
            "4         2              1.0           1.44         1.0                 0.0   \n",
            "\n",
            "   PULocationID  DOLocationID  payment_type  fare_amount  extra  ...  tavg  \\\n",
            "0           107           209             1         10.0    0.5  ...   2.6   \n",
            "1           209           170             1         17.0    2.5  ...  -1.5   \n",
            "2           141           163             1          7.0    0.0  ...  -2.2   \n",
            "3           162           186             1          7.5    1.0  ...   6.5   \n",
            "4           100           164             1         12.0    0.0  ...  -0.6   \n",
            "\n",
            "   tmin  tmax  wspd    pres  trip_duration  pickup_hour  pickup_minute  \\\n",
            "0  -0.6   6.7  13.4  1016.6             11           22             38   \n",
            "1  -4.4   3.3   8.9  1030.8             13           15             21   \n",
            "2  -5.0   2.8  10.2  1028.5              8           15             15   \n",
            "3   3.3  11.7  10.6  1027.4              8           16             45   \n",
            "4  -3.3   2.2   9.1  1038.8             18           10             05   \n",
            "\n",
            "   day_of_month  day_of_week  \n",
            "0             8            3  \n",
            "1            21            2  \n",
            "2            18            6  \n",
            "3            24            5  \n",
            "4             9            4  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "(989755, 26)\n"
          ]
        }
      ],
      "source": [
        "df = df_taxi.merge(df_temp,\n",
        "                   how='left'\n",
        "                   ,on='date')\n",
        "df['trip_duration'] = pd.Series(map(lambda x: (x.seconds % 3600) // 60,df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime'])) \n",
        "# df.drop(columns=['date'],inplace=True)\n",
        "df['pickup_hour'] = pd.Series(map(lambda x: str(x.strftime('%k')), df['tpep_pickup_datetime'])) \n",
        "# df['dropoff_hour'] = pd.Series(map(lambda x: str(x.strftime('%k')), df['tpep_dropoff_datetime'])) \n",
        "df['pickup_minute'] = pd.Series(map(lambda x: str(x.strftime('%M')), df['tpep_pickup_datetime'])) \n",
        "# df['dropoff_minute'] = pd.Series(map(lambda x: str(x.strftime('%M')), df['tpep_dropoff_datetime'])) \n",
        "df['day_of_month'] = pd.Series(map(lambda x: int(x.strftime('%e')) ,df['date']))\n",
        "df['day_of_week'] = pd.Series(map(lambda x: int(x.strftime('%u')) ,df['date']))\n",
        "del df_taxi,df_temp\n",
        "df.drop(columns=['tpep_pickup_datetime','tpep_dropoff_datetime','date'],inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "print(df.head(5))\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "tvo56y6X9YUH",
        "outputId": "58f2b57d-aa1f-4a6c-fe82-326d72562f46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-878e5b7b-89f8-4847-ac44-b0e9142177f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>PULocationID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>...</th>\n",
              "      <th>tavg</th>\n",
              "      <th>tmin</th>\n",
              "      <th>tmax</th>\n",
              "      <th>wspd</th>\n",
              "      <th>pres</th>\n",
              "      <th>trip_duration</th>\n",
              "      <th>pickup_hour</th>\n",
              "      <th>pickup_minute</th>\n",
              "      <th>day_of_month</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-878e5b7b-89f8-4847-ac44-b0e9142177f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-878e5b7b-89f8-4847-ac44-b0e9142177f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-878e5b7b-89f8-4847-ac44-b0e9142177f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [VendorID, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge, tavg, tmin, tmax, wspd, pres, trip_duration, pickup_hour, pickup_minute, day_of_month, day_of_week]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 26 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['tavg'].isnull()]#.isnull().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxrLbcvDauhG"
      },
      "source": [
        "Not performing EDA since this was done during the first project, skipping straight to regression analysis part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_waP_snM9uqu"
      },
      "outputs": [],
      "source": [
        "#splitting the dataset into 80/20 ratios\n",
        "X = df.drop(columns=['trip_duration']).values\n",
        "y = df['trip_duration'].values\n",
        "# del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bF0Bywn39_H",
        "outputId": "8b88cbbd-6b67-4c02-f5e2-06fb56de089d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(791804, 25)\n",
            "(197951, 25)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "\n",
        "#adding another split to randomly reduce number of training rows to about 60 to speed up model training\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.80, random_state = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "# sys.exit('abc')\n",
        "# del X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woznKnyZ5F8M"
      },
      "outputs": [],
      "source": [
        "#performing feature scaaling to 1/ ease computations and 2/ not having an independent variables dominating all the other independent variables\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVqGPgR1ouxR",
        "outputId": "6ea94e4a-a024-42f0-8453-8f3237588415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With 15 principal components instead of 25 components I still obtain 88.93 % of the variance\n"
          ]
        }
      ],
      "source": [
        "#performing PCA to ease computations as well\n",
        "from sklearn.decomposition import PCA\n",
        "number_of_components = 15\n",
        "pca = PCA(n_components = number_of_components)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(f'With {number_of_components} principal components instead of {len(df.columns)-1} components I still obtain {round(sum(explained_variance)*100,2)} % of the variance')\n",
        "# sys.exit('abc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d1tMNnQ6snQ"
      },
      "source": [
        "# Training the NNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urx2BsGl6rxX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Input\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objects as go\n",
        "from keras.callbacks import TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbVS1LlFEN3t"
      },
      "source": [
        "## 1/ MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p94bsn2XcC8a"
      },
      "source": [
        "https://www.baeldung.com/cs/mlp-vs-dnn#:~:text=MLPs%20are%20neural%20networks%20with,to%20traditional%20machine%20learning%20algorithms.\n",
        "according to this website, the main difference between a MLP and a DNN is the # of hidden layers. A MLP has fewer hidden layers than a DNN, among other things."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiWr1FAGYKxm"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(\n",
        "    shape=(X_train.shape[1],)#(32,)\n",
        "    ,name='inputLayer'\n",
        "))\n",
        "model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0)) #hidden layer # of nodes = avg # of nodes of the input and output layer\n",
        "              , kernel_initializer = 'uniform' #initialize the weights according to a uniform distribution and close to 0\n",
        "              , activation = 'relu' \n",
        "              , name = 'hiddenLayer1'\n",
        "              )) \n",
        "model.add(Dense(units = 1\n",
        "              , kernel_initializer = 'uniform' \n",
        "              , activation = 'linear' \n",
        "              , name = 'outputLayer'\n",
        "              ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35hSI-ivXVsO"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam'\n",
        "    ,loss='mse' #chose mse as a loss function because it can be proven that MSE is equal to the bias squared plus the variance, \n",
        "                #so minimizing this metric can reduce both bias and variance and therefore helps fighting back overfitting and underfitting\n",
        "    ,metrics=['mae','mse']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1BYh32xd-dk",
        "outputId": "656b826b-7643-4689-bbab-a2a3490f1cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 137\n",
            "Trainable params: 137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRN4hA3VeAtg",
        "outputId": "2b2aa985-8460-44a8-c405-9c776028f72e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "19902/24744 [=======================>......] - ETA: 9s - loss: 42.4230 - mae: 4.2473 - mse: 42.4230"
          ]
        }
      ],
      "source": [
        "#Fitting the MLP to the training set\n",
        "tensorboard_callback = TensorBoard(\n",
        "    log_dir = 'tboards/log/MLPAdam100Epochs'\n",
        "    ,histogram_freq=1\n",
        "    ,write_graph=True\n",
        "    ,write_images=False\n",
        "    ,update_freq='epoch'\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)# ,min_delta=0.05          \n",
        "model_history = model.fit(X_train,y_train\n",
        "          ,batch_size=32#default value\n",
        "          ,epochs=100\n",
        "          ,validation_data = (X_test,y_test)\n",
        "          ,callbacks=[tensorboard_callback,early_stopping]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szbDE-JBqbBi"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  model_history = pd.DataFrame(model_history.history)\n",
        "  model_history['epoch'] = model_history.index+1\n",
        "except:\n",
        "  pass\n",
        "trace0 = go.Scatter(x=model_history['epoch']\n",
        "                    ,y=model_history['mse']\n",
        "                    ,mode='lines+markers'\n",
        "                    ,name='MLPTrain')\n",
        "trace1 = go.Scatter(x=model_history['epoch']\n",
        "                    ,y=model_history['val_mse']\n",
        "                    ,mode='lines+markers'\n",
        "                    ,name='MLPTest')\n",
        "layout = go.Layout(title='MSE results through the epochs')\n",
        "fig = go.Figure(data = [trace0,trace1]\n",
        "                ,layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHbL9fHjEThc"
      },
      "source": [
        "## 2/ Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLdC2vv7Ve5R"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(\n",
        "    shape=(X_train.shape[1],)\n",
        "    ,name='inputLayer'\n",
        "))\n",
        "model.add(Dense(units = 32#int(round((X_train.shape[1]+1)/2,0))\n",
        "              , kernel_initializer = 'uniform'\n",
        "              , activation = None\n",
        "              , name = 'hiddenLayer1'\n",
        "              ))\n",
        "# model.add(Dense(units = 1#int(round((X_train.shape[1]+1)/2,0))\n",
        "#               , kernel_initializer = 'uniform'\n",
        "#               , activation = None\n",
        "#               , name = 'hiddenLayer2'\n",
        "#               ))\n",
        "# model.add(Dense(\n",
        "#     units=1\n",
        "#     ,activation=None\n",
        "#     ,name='outputLayer'\n",
        "# ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVa_uhCCXQYl"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam'\n",
        "    ,loss='mse'\n",
        "    ,metrics=['mae','mse']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDmvp8CyYCDP"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CSfYSrVYDyN"
      },
      "outputs": [],
      "source": [
        "#Fitting the regression model to the training set\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)# ,min_delta=0.05          \n",
        "model_history = model.fit(X_train,y_train\n",
        "          ,batch_size=32#default value\n",
        "          ,epochs=100\n",
        "          ,callbacks=[early_stopping]\n",
        "          ,validation_data = (X_test,y_test)\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h24HF5zEdT8R"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  model_history = pd.DataFrame(model_history.history)\n",
        "  model_history['epoch'] = model_history.index+1\n",
        "except:\n",
        "  pass\n",
        "# model_history['epoch'] = model_history.epoch\n",
        "trace2 = go.Scatter(x=model_history['epoch']\n",
        "                    ,y=model_history['mse']\n",
        "                    ,mode='lines+markers'\n",
        "                    ,name='LRTrain')\n",
        "trace3 = go.Scatter(x=model_history['epoch']\n",
        "                    ,y=model_history['val_mse']\n",
        "                    ,mode='lines+markers'\n",
        "                    ,name='LRTest')\n",
        "layout = go.Layout(title='MSE results through the epochs')\n",
        "fig = go.Figure(data = [trace0,trace1,trace2,trace3]\n",
        "                ,layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERfbiXG0Ae3m"
      },
      "source": [
        "## 3/ DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGmoQSEwAZ4M"
      },
      "outputs": [],
      "source": [
        "#instantiating the model\n",
        "model = Sequential()\n",
        "#adding input and hidden layers\n",
        "model.add(Input(\n",
        "    shape=(X_train.shape[1],)#(32,)\n",
        "    ,name='inputLayer'\n",
        "))\n",
        "model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "              , kernel_initializer = 'uniform'\n",
        "              , activation = 'relu' \n",
        "              , name = 'hiddenLayer1'\n",
        "              )) \n",
        "model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "              , kernel_initializer = 'uniform'\n",
        "              , activation = 'relu' \n",
        "              , name = 'hiddenLayer2'\n",
        "              )) \n",
        "model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "              , kernel_initializer = 'uniform'\n",
        "              , activation = 'relu' \n",
        "              , name = 'hiddenLayer3'\n",
        "              ))\n",
        "model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "              , kernel_initializer = 'uniform'\n",
        "              , activation = 'relu' \n",
        "              , name = 'hiddenLayer4'\n",
        "              ))\n",
        "#adding the output layer\n",
        "\n",
        "model.add(Dense(units = 1\n",
        "              , kernel_initializer = 'uniform' \n",
        "              , activation = 'linear' \n",
        "              , name = 'outputLayer'\n",
        "              ))#softmax function: equivalent of sigmoid function for a dependent variable that has more than 2 categories (multi label classification)\n",
        "# sys.exit('abc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQAPMLWdeUts"
      },
      "outputs": [],
      "source": [
        "#compiling the DNN\n",
        "model.compile(\n",
        "    optimizer='adam'#tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    ,loss='mse'\n",
        "    ,metrics=['mae','mse']\n",
        ")\n",
        "#perceptron model -> simple neural network with one neuron - and take a sigmoid activation function, you obtain a logistic regression function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAGsVyY7AaWG"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lj5xO9UjEqb"
      },
      "outputs": [],
      "source": [
        "#Fitting the DNN to the training set\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)# ,min_delta=0.05          \n",
        "model_history= model.fit(X_train,y_train\n",
        "          ,batch_size=32#default value\n",
        "          ,epochs=100\n",
        "          ,callbacks=[early_stopping]\n",
        "          ,validation_data = (X_test,y_test)\n",
        "          # ,patience=0\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okPrlpsDdkgL"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  model_history = pd.DataFrame(model_history.history)\n",
        "  model_history['epoch'] = model_history.index+1\n",
        "except:\n",
        "  pass\n",
        "trace4 = go.Scatter(x=model_history['epoch']\n",
        "                    ,y=model_history['mse']\n",
        "                    ,mode='lines+markers'\n",
        "                    ,name='DNNTrain')\n",
        "trace5 = go.Scatter(x=model_history['epoch']\n",
        "                    ,y=model_history['val_mse']\n",
        "                    ,mode='lines+markers'\n",
        "                    ,name='DNNTest')\n",
        "layout = go.Layout(title='MSE results through the epochs'\n",
        "                   ,xaxis=dict(title='Number of epochs')\n",
        "                   ,yaxis=dict(title='MSE')\n",
        "                   )\n",
        "fig = go.Figure(data = [trace0,trace1,trace2,trace3,trace4,trace5]\n",
        "                ,layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00kWoJhjMdih"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_true=y_test\n",
        "                         ,y_pred=y_pred)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB05w8bwnoLj"
      },
      "source": [
        "# Hyperparameter tuning using GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bsQFyRUxn06g",
        "outputId": "ea00c852-47ab-4429-df64-5949db4c5e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: DeprecationWarning:\n",
            "\n",
            "KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2851/2851 [==============================] - 6s 2ms/step - loss: 54.8256 - mae: 4.9109 - mse: 54.8256\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.5299 - mae: 4.0993 - mse: 37.5299\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 37.1760 - mae: 4.0802 - mse: 37.1760\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.1495 - mae: 4.0719 - mse: 37.1495\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.0009 - mae: 4.0636 - mse: 37.0009\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.8933 - mae: 4.0651 - mse: 36.8933\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.7210 - mae: 4.0585 - mse: 36.7210\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.5256 - mae: 4.0490 - mse: 36.5256\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.4001 - mae: 4.0333 - mse: 36.4001\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.1822 - mae: 4.0213 - mse: 36.1822\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.9080 - mae: 4.0089 - mse: 35.9080\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.7123 - mae: 3.9874 - mse: 35.7123\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 35.4645 - mae: 3.9663 - mse: 35.4645\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.1590 - mae: 3.9416 - mse: 35.1590\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.9249 - mae: 3.9420 - mse: 34.9249\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.6051 - mae: 3.9031 - mse: 34.6051\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.4108 - mae: 3.8975 - mse: 34.4108\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.1618 - mae: 3.8705 - mse: 34.1618\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 9s 3ms/step - loss: 33.8072 - mae: 3.8475 - mse: 33.8072\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.6266 - mae: 3.8356 - mse: 33.6266\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4609 - mae: 3.8217 - mse: 33.4609\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.3169 - mae: 3.8101 - mse: 33.3169\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3380 - mae: 3.8054 - mse: 33.3380\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2579 - mae: 3.8039 - mse: 33.2579\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2395 - mae: 3.7994 - mse: 33.2395\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 46.7815 - mae: 4.2639 - mse: 46.7815\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 25.1924 - mae: 2.8794 - mse: 25.1923\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.8207 - mae: 2.8672 - mse: 24.8207\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.5790 - mae: 2.8650 - mse: 24.5790\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.4910 - mae: 2.8593 - mse: 24.4910\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4346 - mae: 2.8601 - mse: 24.4346\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3613 - mae: 2.8569 - mse: 24.3613\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.3014 - mae: 2.8503 - mse: 24.3014\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.3159 - mae: 2.8530 - mse: 24.3159\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.2491 - mae: 2.8506 - mse: 24.2491\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.2045 - mae: 2.8482 - mse: 24.2045\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.1789 - mae: 2.8375 - mse: 24.1789\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.0925 - mae: 2.8354 - mse: 24.0925\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.0569 - mae: 2.8292 - mse: 24.0569\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.9992 - mae: 2.8226 - mse: 23.9992\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.9229 - mae: 2.8116 - mse: 23.9229\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.7731 - mae: 2.7943 - mse: 23.7731\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.4880 - mae: 2.7561 - mse: 23.4880\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.3658 - mae: 2.7433 - mse: 23.3658\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.1470 - mae: 2.7121 - mse: 23.1470\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 22.9372 - mae: 2.6789 - mse: 22.9372\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 22.7066 - mae: 2.6557 - mse: 22.7066\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 22.5107 - mae: 2.6297 - mse: 22.5107\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 22.2394 - mae: 2.5984 - mse: 22.2394\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 21.9049 - mae: 2.5734 - mse: 21.9049\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 48.6247 - mae: 4.6187 - mse: 48.6247\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 29.7832 - mae: 3.4280 - mse: 29.7832\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 25.2081 - mae: 2.9272 - mse: 25.2081\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.9557 - mae: 2.9026 - mse: 24.9557\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.7890 - mae: 2.8948 - mse: 24.7890\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.8610 - mae: 2.8802 - mse: 24.8610\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.7057 - mae: 2.8792 - mse: 24.7057\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.6711 - mae: 2.8749 - mse: 24.6711\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.6611 - mae: 2.8718 - mse: 24.6611\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.6213 - mae: 2.8645 - mse: 24.6213\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.5941 - mae: 2.8626 - mse: 24.5941\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.4556 - mae: 2.8539 - mse: 24.4556\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.3261 - mae: 2.8395 - mse: 24.3261\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.1915 - mae: 2.8312 - mse: 24.1915\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.1429 - mae: 2.8235 - mse: 24.1429\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.9784 - mae: 2.8121 - mse: 23.9784\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.9610 - mae: 2.8130 - mse: 23.9610\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.0351 - mae: 2.8078 - mse: 24.0351\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.8328 - mae: 2.8066 - mse: 23.8328\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 23.8531 - mae: 2.8045 - mse: 23.8531\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.7411 - mae: 2.7963 - mse: 23.7411\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.7566 - mae: 2.7805 - mse: 23.7566\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.3534 - mae: 2.7186 - mse: 23.3534\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.0144 - mae: 2.6795 - mse: 23.0144\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 22.7129 - mae: 2.6479 - mse: 22.7129\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 53.4518 - mae: 4.8416 - mse: 53.4518\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.4541 - mae: 4.1052 - mse: 37.4541\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.1552 - mae: 4.0766 - mse: 37.1552\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 37.0376 - mae: 4.0654 - mse: 37.0376\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.8369 - mae: 4.0581 - mse: 36.8369\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.6214 - mae: 4.0455 - mse: 36.6214\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.4376 - mae: 4.0350 - mse: 36.4376\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.1656 - mae: 4.0148 - mse: 36.1656\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.8646 - mae: 3.9963 - mse: 35.8646\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.6406 - mae: 3.9778 - mse: 35.6406\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.3294 - mae: 3.9559 - mse: 35.3294\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.0392 - mae: 3.9312 - mse: 35.0392\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.6781 - mae: 3.9081 - mse: 34.6781\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.3626 - mae: 3.8864 - mse: 34.3626\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.9875 - mae: 3.8597 - mse: 33.9875\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.6440 - mae: 3.8332 - mse: 33.6440\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4749 - mae: 3.8237 - mse: 33.4749\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4021 - mae: 3.8173 - mse: 33.4021\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4246 - mae: 3.8088 - mse: 33.4246\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2890 - mae: 3.7962 - mse: 33.2890\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3259 - mae: 3.8025 - mse: 33.3259\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3122 - mae: 3.8032 - mse: 33.3122\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.2625 - mae: 3.8001 - mse: 33.2625\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3669 - mae: 3.8040 - mse: 33.3669\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3127 - mae: 3.7917 - mse: 33.3127\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 49.9313 - mae: 4.6957 - mse: 49.9313\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.3250 - mae: 4.0880 - mse: 37.3250\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.1773 - mae: 4.0813 - mse: 37.1773\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.7912 - mae: 4.0470 - mse: 36.7912\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.3358 - mae: 4.0248 - mse: 36.3358\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.8840 - mae: 3.9964 - mse: 35.8840\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 35.3429 - mae: 3.9657 - mse: 35.3429\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.9769 - mae: 3.9381 - mse: 34.9769\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.4873 - mae: 3.8919 - mse: 34.4873\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.9646 - mae: 3.8677 - mse: 33.9646\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.6895 - mae: 3.8415 - mse: 33.6895\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.5877 - mae: 3.8291 - mse: 33.5877\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4743 - mae: 3.8226 - mse: 33.4743\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3296 - mae: 3.8159 - mse: 33.3296\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3773 - mae: 3.8172 - mse: 33.3773\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4051 - mae: 3.8170 - mse: 33.4051\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.3273 - mae: 3.8165 - mse: 33.3273\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3579 - mae: 3.8139 - mse: 33.3579\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4068 - mae: 3.8133 - mse: 33.4068\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3642 - mae: 3.8119 - mse: 33.3642\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3459 - mae: 3.8158 - mse: 33.3459\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1308 - mae: 3.8088 - mse: 33.1308\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4001 - mae: 3.8195 - mse: 33.4001\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2810 - mae: 3.8141 - mse: 33.2810\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2079 - mae: 3.8149 - mse: 33.2079\n",
            "248/248 [==============================] - 1s 2ms/step\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 54.5560 - mae: 4.8649 - mse: 54.5560\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.5989 - mae: 4.1091 - mse: 37.5989\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.2622 - mae: 4.0785 - mse: 37.2622\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.8423 - mae: 4.0571 - mse: 36.8423\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.7144 - mae: 4.0594 - mse: 36.7144\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.3962 - mae: 4.0192 - mse: 36.3962\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 36.1240 - mae: 4.0077 - mse: 36.1240\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.7443 - mae: 3.9855 - mse: 35.7443\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.3654 - mae: 3.9606 - mse: 35.3654\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 35.0047 - mae: 3.9286 - mse: 35.0047\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.6221 - mae: 3.9010 - mse: 34.6221\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.2712 - mae: 3.8732 - mse: 34.2712\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.8427 - mae: 3.8483 - mse: 33.8427\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.7219 - mae: 3.8287 - mse: 33.7219\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.6221 - mae: 3.8174 - mse: 33.6221\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4925 - mae: 3.8131 - mse: 33.4925\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.5239 - mae: 3.8097 - mse: 33.5239\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1606 - mae: 3.7811 - mse: 33.1606\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 28.0507 - mae: 3.3240 - mse: 28.0507\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 25.5343 - mae: 3.0302 - mse: 25.5343\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.7781 - mae: 2.9213 - mse: 24.7781\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.5197 - mae: 2.8795 - mse: 24.5197\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.4102 - mae: 2.8614 - mse: 24.4102\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.2926 - mae: 2.8501 - mse: 24.2926\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.3306 - mae: 2.8480 - mse: 24.3306\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 49.9756 - mae: 4.7049 - mse: 49.9756\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.2534 - mae: 4.0863 - mse: 37.2534\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.0181 - mae: 4.0714 - mse: 37.0181\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 36.7030 - mae: 4.0555 - mse: 36.7030\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.4233 - mae: 4.0306 - mse: 36.4233\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.1298 - mae: 4.0127 - mse: 36.1298\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.6951 - mae: 3.9854 - mse: 35.6951\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.2319 - mae: 3.9595 - mse: 35.2319\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.8826 - mae: 3.9303 - mse: 34.8826\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.4596 - mae: 3.9000 - mse: 34.4596\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.9867 - mae: 3.8709 - mse: 33.9867\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.7316 - mae: 3.8456 - mse: 33.7316\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.5550 - mae: 3.8290 - mse: 33.5550\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.4704 - mae: 3.8251 - mse: 33.4704\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4026 - mae: 3.8183 - mse: 33.4026\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3938 - mae: 3.8153 - mse: 33.3938\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3553 - mae: 3.8155 - mse: 33.3553\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3894 - mae: 3.8120 - mse: 33.3894\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3000 - mae: 3.8176 - mse: 33.3000\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3746 - mae: 3.8091 - mse: 33.3746\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.4962 - mae: 3.8210 - mse: 33.4962\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2451 - mae: 3.8092 - mse: 33.2451\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 25.3803 - mae: 2.9437 - mse: 25.3803\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.9172 - mae: 2.7954 - mse: 23.9172\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.7105 - mae: 2.7860 - mse: 23.7105\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 53.2236 - mae: 4.8453 - mse: 53.2236\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.7266 - mae: 4.1007 - mse: 37.7266\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.2660 - mae: 4.0845 - mse: 37.2660\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.0724 - mae: 4.0649 - mse: 37.0724\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.8018 - mae: 4.0582 - mse: 36.8018\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.6217 - mae: 4.0351 - mse: 36.6217\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.4664 - mae: 4.0314 - mse: 36.4664\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 36.2435 - mae: 4.0183 - mse: 36.2435\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.0673 - mae: 3.9991 - mse: 36.0673\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.7408 - mae: 3.9858 - mse: 35.7408\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.4918 - mae: 3.9605 - mse: 35.4918\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.1135 - mae: 3.9423 - mse: 35.1135\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.9251 - mae: 3.9173 - mse: 34.9251\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.4881 - mae: 3.8938 - mse: 34.4881\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.2483 - mae: 3.8607 - mse: 34.2483\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.9261 - mae: 3.8505 - mse: 33.9261\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.6947 - mae: 3.8308 - mse: 33.6947\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.6465 - mae: 3.8132 - mse: 33.6465\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4438 - mae: 3.8110 - mse: 33.4438\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4671 - mae: 3.7976 - mse: 33.4671\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4798 - mae: 3.8034 - mse: 33.4798\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3910 - mae: 3.8005 - mse: 33.3910\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.5120 - mae: 3.8138 - mse: 33.5120\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3785 - mae: 3.8037 - mse: 33.3785\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3824 - mae: 3.8037 - mse: 33.3824\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 49.7612 - mae: 4.6873 - mse: 49.7612\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 37.0162 - mae: 4.0825 - mse: 37.0162\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.8630 - mae: 4.0631 - mse: 36.8630\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.5925 - mae: 4.0528 - mse: 36.5925\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.3365 - mae: 4.0379 - mse: 36.3365\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.7363 - mae: 4.0048 - mse: 35.7363\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 35.4784 - mae: 3.9828 - mse: 35.4784\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.0716 - mae: 3.9512 - mse: 35.0716\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 34.6882 - mae: 3.9158 - mse: 34.6882\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.9502 - mae: 3.8754 - mse: 33.9502\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.6727 - mae: 3.8505 - mse: 33.6727\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.4247 - mae: 3.8205 - mse: 33.4247\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2435 - mae: 3.8180 - mse: 33.2435\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2099 - mae: 3.8104 - mse: 33.2099\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1229 - mae: 3.7948 - mse: 33.1229\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1483 - mae: 3.8030 - mse: 33.1483\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2135 - mae: 3.8038 - mse: 33.2135\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1701 - mae: 3.8053 - mse: 33.1701\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1985 - mae: 3.8085 - mse: 33.1985\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.0949 - mae: 3.8045 - mse: 33.0949\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.0856 - mae: 3.7994 - mse: 33.0856\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1446 - mae: 3.7977 - mse: 33.1446\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1084 - mae: 3.7995 - mse: 33.1084\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.0038 - mae: 3.7973 - mse: 33.0038\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1042 - mae: 3.8026 - mse: 33.1042\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 50.0349 - mae: 4.7089 - mse: 50.0349\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.9294 - mae: 4.0778 - mse: 36.9294\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.6217 - mae: 4.0499 - mse: 36.6217\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.3011 - mae: 4.0379 - mse: 36.3011\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 36.1235 - mae: 4.0195 - mse: 36.1235\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.7135 - mae: 3.9924 - mse: 35.7135\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.1847 - mae: 3.9639 - mse: 35.1847\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.7513 - mae: 3.9297 - mse: 34.7513\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 34.3365 - mae: 3.8971 - mse: 34.3365\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.9382 - mae: 3.8693 - mse: 33.9382\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4232 - mae: 3.8363 - mse: 33.4232\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2645 - mae: 3.8204 - mse: 33.2645\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.0391 - mae: 3.7989 - mse: 33.0391\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.0249 - mae: 3.7989 - mse: 33.0249\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 32.9532 - mae: 3.7903 - mse: 32.9532\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 32.9041 - mae: 3.7916 - mse: 32.9041\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 32.8994 - mae: 3.7926 - mse: 32.8994\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 32.8602 - mae: 3.7858 - mse: 32.8602\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 30.7221 - mae: 3.6071 - mse: 30.7221\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 26.0163 - mae: 3.1147 - mse: 26.0163\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.6528 - mae: 2.9320 - mse: 24.6528\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.2683 - mae: 2.8768 - mse: 24.2683\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.1215 - mae: 2.8460 - mse: 24.1215\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.0390 - mae: 2.8379 - mse: 24.0390\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.0359 - mae: 2.8293 - mse: 24.0359\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 54.3413 - mae: 4.8255 - mse: 54.3413\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.5076 - mae: 4.0378 - mse: 37.5076\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.3629 - mae: 4.0217 - mse: 37.3629\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.1725 - mae: 4.0271 - mse: 37.1725\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.0616 - mae: 4.0110 - mse: 37.0616\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.9547 - mae: 4.0154 - mse: 36.9547\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 7s 3ms/step - loss: 36.8075 - mae: 4.0063 - mse: 36.8075\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.8463 - mae: 3.9994 - mse: 36.8463\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.5533 - mae: 3.9935 - mse: 36.5533\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.4558 - mae: 3.9793 - mse: 36.4558\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.0698 - mae: 3.9597 - mse: 36.0698\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.8845 - mae: 3.9433 - mse: 35.8845\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.4209 - mae: 3.9166 - mse: 35.4209\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.0900 - mae: 3.8929 - mse: 35.0900\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.8731 - mae: 3.8730 - mse: 34.8731\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 7s 3ms/step - loss: 34.3781 - mae: 3.8456 - mse: 34.3781\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.1479 - mae: 3.8216 - mse: 34.1479\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.8567 - mae: 3.7929 - mse: 33.8567\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.6045 - mae: 3.7870 - mse: 33.6045\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.6114 - mae: 3.7751 - mse: 33.6114\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.5260 - mae: 3.7715 - mse: 33.5260\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.5787 - mae: 3.7683 - mse: 33.5787\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.5505 - mae: 3.7682 - mse: 33.5505\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4671 - mae: 3.7622 - mse: 33.4671\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.4678 - mae: 3.7655 - mse: 33.4678\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 54.2890 - mae: 4.8200 - mse: 54.2890\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.3877 - mae: 4.0223 - mse: 37.3877\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.1467 - mae: 4.0051 - mse: 37.1467\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.9216 - mae: 4.0080 - mse: 36.9216\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.8643 - mae: 4.0040 - mse: 36.8643\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.7891 - mae: 3.9985 - mse: 36.7891\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.6869 - mae: 3.6472 - mse: 33.6869\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 25.6308 - mae: 2.8761 - mse: 25.6308\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 25.0138 - mae: 2.8446 - mse: 25.0138\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.7468 - mae: 2.8328 - mse: 24.7468\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.5174 - mae: 2.8244 - mse: 24.5174\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4652 - mae: 2.8194 - mse: 24.4652\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.4536 - mae: 2.8154 - mse: 24.4536\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.3380 - mae: 2.8148 - mse: 24.3380\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3058 - mae: 2.8135 - mse: 24.3058\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.2992 - mae: 2.8068 - mse: 24.2992\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.2062 - mae: 2.8059 - mse: 24.2062\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.1587 - mae: 2.8000 - mse: 24.1587\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.0851 - mae: 2.7960 - mse: 24.0851\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.0030 - mae: 2.7936 - mse: 24.0030\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.9032 - mae: 2.7879 - mse: 23.9032\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.7713 - mae: 2.7740 - mse: 23.7713\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.5980 - mae: 2.7592 - mse: 23.5980\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.2786 - mae: 2.7387 - mse: 23.2786\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.0171 - mae: 2.7184 - mse: 23.0171\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 8s 2ms/step - loss: 50.8273 - mae: 4.5809 - mse: 50.8273\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 25.8669 - mae: 2.9039 - mse: 25.8669\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 25.1254 - mae: 2.8546 - mse: 25.1254\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.9323 - mae: 2.8511 - mse: 24.9323\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.8751 - mae: 2.8472 - mse: 24.8751\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.7439 - mae: 2.8457 - mse: 24.7439\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.6208 - mae: 2.8402 - mse: 24.6208\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4928 - mae: 2.8388 - mse: 24.4928\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4231 - mae: 2.8356 - mse: 24.4231\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3474 - mae: 2.8326 - mse: 24.3474\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3420 - mae: 2.8295 - mse: 24.3420\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3159 - mae: 2.8252 - mse: 24.3159\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.2376 - mae: 2.8210 - mse: 24.2376\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.1494 - mae: 2.8147 - mse: 24.1494\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.0962 - mae: 2.8108 - mse: 24.0962\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.9896 - mae: 2.8012 - mse: 23.9896\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.9586 - mae: 2.7920 - mse: 23.9586\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.8139 - mae: 2.7837 - mse: 23.8139\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.6476 - mae: 2.7640 - mse: 23.6476\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.4856 - mae: 2.7395 - mse: 23.4856\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.2694 - mae: 2.7218 - mse: 23.2694\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.1147 - mae: 2.7096 - mse: 23.1147\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 22.9315 - mae: 2.6961 - mse: 22.9315\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 22.7575 - mae: 2.6794 - mse: 22.7574\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 22.4651 - mae: 2.6574 - mse: 22.4651\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 49.8500 - mae: 4.4923 - mse: 49.8500\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 25.5477 - mae: 2.8906 - mse: 25.5477\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 25.0284 - mae: 2.8572 - mse: 25.0284\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.9335 - mae: 2.8562 - mse: 24.9335\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.7923 - mae: 2.8530 - mse: 24.7923\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.7727 - mae: 2.8566 - mse: 24.7727\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 24.7640 - mae: 2.8513 - mse: 24.7640\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.6877 - mae: 2.8502 - mse: 24.6877\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.5958 - mae: 2.8482 - mse: 24.5958\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.5245 - mae: 2.8457 - mse: 24.5245\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4866 - mae: 2.8420 - mse: 24.4866\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.4098 - mae: 2.8359 - mse: 24.4098\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4269 - mae: 2.8325 - mse: 24.4269\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3104 - mae: 2.8219 - mse: 24.3104\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.1913 - mae: 2.8032 - mse: 24.1913\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.0514 - mae: 2.7816 - mse: 24.0514\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.9276 - mae: 2.7703 - mse: 23.9276\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.8039 - mae: 2.7620 - mse: 23.8039\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.6276 - mae: 2.7472 - mse: 23.6276\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.5762 - mae: 2.7405 - mse: 23.5762\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.4850 - mae: 2.7287 - mse: 23.4850\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 23.2956 - mae: 2.7132 - mse: 23.2956\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 23.2113 - mae: 2.6951 - mse: 23.2113\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 22.9391 - mae: 2.6761 - mse: 22.9391\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 22.6375 - mae: 2.6514 - mse: 22.6375\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 53.2982 - mae: 4.7832 - mse: 53.2982\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.4949 - mae: 4.0398 - mse: 37.4949\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.1817 - mae: 4.0319 - mse: 37.1817\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.1001 - mae: 4.0203 - mse: 37.1001\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.9210 - mae: 4.0080 - mse: 36.9210\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.5699 - mae: 3.9901 - mse: 36.5699\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.1901 - mae: 3.9697 - mse: 36.1901\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.9297 - mae: 3.9408 - mse: 35.9297\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.5022 - mae: 3.9258 - mse: 35.5022\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.0703 - mae: 3.8964 - mse: 35.0703\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.6816 - mae: 3.8643 - mse: 34.6816\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.1882 - mae: 3.8360 - mse: 34.1882\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.8732 - mae: 3.8102 - mse: 33.8732\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.6543 - mae: 3.7950 - mse: 33.6543\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4925 - mae: 3.7862 - mse: 33.4925\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4948 - mae: 3.7813 - mse: 33.4948\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.4004 - mae: 3.7727 - mse: 33.4004\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.5234 - mae: 3.7701 - mse: 33.5234\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4755 - mae: 3.7745 - mse: 33.4755\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4819 - mae: 3.7742 - mse: 33.4819\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3015 - mae: 3.7723 - mse: 33.3015\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 32.6708 - mae: 3.7194 - mse: 32.6708\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 27.8587 - mae: 3.2921 - mse: 27.8587\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 25.3525 - mae: 3.0042 - mse: 25.3525\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.5843 - mae: 2.9045 - mse: 24.5843\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 53.6469 - mae: 4.6961 - mse: 53.6469\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 26.0382 - mae: 2.9241 - mse: 26.0382\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 25.1770 - mae: 2.8508 - mse: 25.1770\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 25.0032 - mae: 2.8453 - mse: 25.0032\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.8232 - mae: 2.8459 - mse: 24.8232\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.8114 - mae: 2.8466 - mse: 24.8114\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.7613 - mae: 2.8441 - mse: 24.7613\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.6516 - mae: 2.8439 - mse: 24.6516\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.6214 - mae: 2.8385 - mse: 24.6214\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.5085 - mae: 2.8371 - mse: 24.5085\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4744 - mae: 2.8270 - mse: 24.4744\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.4610 - mae: 2.8175 - mse: 24.4610\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3991 - mae: 2.8120 - mse: 24.3991\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.2545 - mae: 2.8043 - mse: 24.2545\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.1711 - mae: 2.7995 - mse: 24.1711\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.2097 - mae: 2.7892 - mse: 24.2097\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.0143 - mae: 2.7821 - mse: 24.0143\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 23.9030 - mae: 2.7689 - mse: 23.9030\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.7751 - mae: 2.7581 - mse: 23.7751\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.6415 - mae: 2.7419 - mse: 23.6415\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.4471 - mae: 2.7263 - mse: 23.4471\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.3596 - mae: 2.7126 - mse: 23.3596\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 23.1573 - mae: 2.6945 - mse: 23.1573\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 22.8995 - mae: 2.6704 - mse: 22.8995\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 22.7360 - mae: 2.6545 - mse: 22.7360\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 56.4553 - mae: 4.9396 - mse: 56.4553\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 37.4536 - mae: 4.0409 - mse: 37.4536\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.2877 - mae: 4.0193 - mse: 37.2877\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.0347 - mae: 4.0170 - mse: 37.0347\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 36.8727 - mae: 4.0104 - mse: 36.8727\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.8029 - mae: 4.0056 - mse: 36.8029\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.7285 - mae: 4.0067 - mse: 36.7285\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.6964 - mae: 3.9946 - mse: 36.6964\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.4257 - mae: 3.9794 - mse: 36.4257\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.0116 - mae: 3.9671 - mse: 36.0116\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.7184 - mae: 3.9392 - mse: 35.7184\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 35.3721 - mae: 3.9178 - mse: 35.3721\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.1009 - mae: 3.8880 - mse: 35.1009\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.7543 - mae: 3.8618 - mse: 34.7543\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.3182 - mae: 3.8429 - mse: 34.3182\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.9512 - mae: 3.8188 - mse: 33.9512\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.6940 - mae: 3.8001 - mse: 33.6940\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.5964 - mae: 3.7830 - mse: 33.5964\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4097 - mae: 3.7713 - mse: 33.4097\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2257 - mae: 3.7627 - mse: 33.2257\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.3194 - mae: 3.7639 - mse: 33.3194\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.3811 - mae: 3.7636 - mse: 33.3811\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.3153 - mae: 3.7629 - mse: 33.3153\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2951 - mae: 3.7555 - mse: 33.2951\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2766 - mae: 3.7590 - mse: 33.2766\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 58.1641 - mae: 4.9993 - mse: 58.1641\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.5000 - mae: 4.0324 - mse: 37.5000\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.1920 - mae: 4.0136 - mse: 37.1920\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.9945 - mae: 4.0005 - mse: 36.9945\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.7705 - mae: 3.9943 - mse: 36.7705\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.5750 - mae: 3.9804 - mse: 36.5750\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.2751 - mae: 3.9585 - mse: 36.2751\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 36.0583 - mae: 3.9449 - mse: 36.0583\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.7153 - mae: 3.9135 - mse: 35.7153\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.4181 - mae: 3.8993 - mse: 35.4181\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.0317 - mae: 3.8690 - mse: 35.0317\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.5707 - mae: 3.8384 - mse: 34.5707\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.1746 - mae: 3.8097 - mse: 34.1746\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 33.9070 - mae: 3.7939 - mse: 33.9070\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.6998 - mae: 3.7819 - mse: 33.6998\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.5672 - mae: 3.7696 - mse: 33.5672\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.3886 - mae: 3.7453 - mse: 33.3886\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 31.1685 - mae: 3.5381 - mse: 31.1685\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 26.6282 - mae: 3.0786 - mse: 26.6282\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.9623 - mae: 2.8719 - mse: 24.9623\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.6091 - mae: 2.8290 - mse: 24.6091\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.3970 - mae: 2.8066 - mse: 24.3970\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 24.2003 - mae: 2.7995 - mse: 24.2003\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.1362 - mae: 2.7939 - mse: 24.1362\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 24.1109 - mae: 2.7896 - mse: 24.1109\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 53.2008 - mae: 4.7983 - mse: 53.2008\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 37.2516 - mae: 4.0285 - mse: 37.2516\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 36.8130 - mae: 4.0131 - mse: 36.8130\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.5076 - mae: 4.0005 - mse: 36.5076\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.3174 - mae: 3.9738 - mse: 36.3174\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.8184 - mae: 3.9537 - mse: 35.8184\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 35.3184 - mae: 3.9186 - mse: 35.3184\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.8270 - mae: 3.8789 - mse: 34.8270\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.3091 - mae: 3.8471 - mse: 34.3091\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.8721 - mae: 3.8154 - mse: 33.8721\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.5917 - mae: 3.7928 - mse: 33.5917\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.3355 - mae: 3.7823 - mse: 33.3355\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2257 - mae: 3.7764 - mse: 33.2257\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.3365 - mae: 3.7693 - mse: 33.3365\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2667 - mae: 3.7672 - mse: 33.2667\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.1345 - mae: 3.7691 - mse: 33.1345\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2315 - mae: 3.7642 - mse: 33.2315\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.2524 - mae: 3.7629 - mse: 33.2524\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.1155 - mae: 3.7651 - mse: 33.1155\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2059 - mae: 3.7602 - mse: 33.2059\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.1643 - mae: 3.7679 - mse: 33.1643\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.1630 - mae: 3.7635 - mse: 33.1630\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.1158 - mae: 3.7623 - mse: 33.1158\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 33.1370 - mae: 3.7603 - mse: 33.1370\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.1393 - mae: 3.7599 - mse: 33.1393\n",
            "248/248 [==============================] - 1s 2ms/step\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 54.7413 - mae: 4.8729 - mse: 54.7413\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 37.1607 - mae: 4.0254 - mse: 37.1607\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.7822 - mae: 4.0156 - mse: 36.7822\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.6590 - mae: 4.0097 - mse: 36.6590\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.4729 - mae: 4.0036 - mse: 36.4729\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.3706 - mae: 4.0000 - mse: 36.3706\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.2553 - mae: 3.9986 - mse: 36.2553\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.2768 - mae: 3.9857 - mse: 36.2768\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.2115 - mae: 3.9851 - mse: 36.2115\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 36.1600 - mae: 3.9862 - mse: 36.1600\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.0093 - mae: 3.9840 - mse: 36.0093\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 36.0425 - mae: 3.9819 - mse: 36.0425\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.9101 - mae: 3.9637 - mse: 35.9101\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.6291 - mae: 3.9512 - mse: 35.6291\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.3827 - mae: 3.9322 - mse: 35.3827\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 35.0936 - mae: 3.9148 - mse: 35.0936\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.7655 - mae: 3.8957 - mse: 34.7655\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 34.4896 - mae: 3.8746 - mse: 34.4896\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 7s 3ms/step - loss: 34.2416 - mae: 3.8498 - mse: 34.2416\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.8359 - mae: 3.8273 - mse: 33.8359\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.5962 - mae: 3.8048 - mse: 33.5962\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.4550 - mae: 3.7892 - mse: 33.4550\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 33.2495 - mae: 3.7757 - mse: 33.2495\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 32.2687 - mae: 3.7086 - mse: 32.2687\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 27.6507 - mae: 3.2743 - mse: 27.6507\n",
            "248/248 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 90.5587 - mae: 6.2380 - mse: 90.5587\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 85.2515 - mae: 6.8137 - mse: 85.2515\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 60.5722 - mae: 5.6633 - mse: 60.5722\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 50.8601 - mae: 5.2756 - mse: 50.8601\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 48.4121 - mae: 5.1100 - mse: 48.4121\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 47.3910 - mae: 5.0164 - mse: 47.3910\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 46.8764 - mae: 4.9694 - mse: 46.8764\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 45.6822 - mae: 4.9115 - mse: 45.6822\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 72.1681 - mae: 6.1916 - mse: 72.1681\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8320 - mae: 6.9000 - mse: 86.8320\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8306 - mae: 6.9012 - mse: 86.8306\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.8318 - mae: 6.9021 - mse: 86.8318\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.8235 - mae: 6.8997 - mse: 86.8235\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8276 - mae: 6.9014 - mse: 86.8276\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8249 - mae: 6.9005 - mse: 86.8249\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8329 - mae: 6.9020 - mse: 86.8329\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8251 - mae: 6.8995 - mse: 86.8251\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8239 - mae: 6.9007 - mse: 86.8239\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8142 - mae: 6.9006 - mse: 86.8142\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8340 - mae: 6.9014 - mse: 86.8340\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8319 - mae: 6.9003 - mse: 86.8319\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.8308 - mae: 6.9026 - mse: 86.8308\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.8240 - mae: 6.9013 - mse: 86.8240\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8218 - mae: 6.9012 - mse: 86.8218\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.8217 - mae: 6.8979 - mse: 86.8217\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 87.5494 - mae: 6.8966 - mse: 87.5494\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1866 - mae: 6.8704 - mse: 86.1866\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1871 - mae: 6.8747 - mse: 86.1871\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1927 - mae: 6.8729 - mse: 86.1927\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1883 - mae: 6.8695 - mse: 86.1883\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1875 - mae: 6.8722 - mse: 86.1875\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.1906 - mae: 6.8722 - mse: 86.1906\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1899 - mae: 6.8749 - mse: 86.1899\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1880 - mae: 6.8727 - mse: 86.1880\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1954 - mae: 6.8724 - mse: 86.1954\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 86.1899 - mae: 6.8706 - mse: 86.1899\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1848 - mae: 6.8716 - mse: 86.1848\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1894 - mae: 6.8748 - mse: 86.1894\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1864 - mae: 6.8706 - mse: 86.1864\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.2011 - mae: 6.8737 - mse: 86.2011\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1865 - mae: 6.8728 - mse: 86.1865\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.1702 - mae: 6.8707 - mse: 86.1702\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1854 - mae: 6.8718 - mse: 86.1854\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1925 - mae: 6.8718 - mse: 86.1925\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1961 - mae: 6.8720 - mse: 86.1961\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1947 - mae: 6.8732 - mse: 86.1947\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1888 - mae: 6.8734 - mse: 86.1888\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1955 - mae: 6.8715 - mse: 86.1955\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1917 - mae: 6.8720 - mse: 86.1917\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.1908 - mae: 6.8727 - mse: 86.1908\n",
            "248/248 [==============================] - 1s 2ms/step\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 91.0264 - mae: 6.9264 - mse: 91.0264\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6403 - mae: 6.8899 - mse: 86.6403\n",
            "Epoch 3/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6404 - mae: 6.8906 - mse: 86.6404\n",
            "Epoch 4/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6390 - mae: 6.8948 - mse: 86.6390\n",
            "Epoch 5/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6427 - mae: 6.8869 - mse: 86.6427\n",
            "Epoch 6/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6477 - mae: 6.8930 - mse: 86.6477\n",
            "Epoch 7/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6489 - mae: 6.8917 - mse: 86.6489\n",
            "Epoch 8/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6409 - mae: 6.8904 - mse: 86.6409\n",
            "Epoch 9/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6519 - mae: 6.8919 - mse: 86.6519\n",
            "Epoch 10/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.6448 - mae: 6.8902 - mse: 86.6448\n",
            "Epoch 11/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.6551 - mae: 6.8926 - mse: 86.6551\n",
            "Epoch 12/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6418 - mae: 6.8915 - mse: 86.6418\n",
            "Epoch 13/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6473 - mae: 6.8917 - mse: 86.6473\n",
            "Epoch 14/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6481 - mae: 6.8900 - mse: 86.6481\n",
            "Epoch 15/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6411 - mae: 6.8923 - mse: 86.6411\n",
            "Epoch 16/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6501 - mae: 6.8908 - mse: 86.6501\n",
            "Epoch 17/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6416 - mae: 6.8903 - mse: 86.6416\n",
            "Epoch 18/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6450 - mae: 6.8924 - mse: 86.6450\n",
            "Epoch 19/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6448 - mae: 6.8908 - mse: 86.6448\n",
            "Epoch 20/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.6351 - mae: 6.8917 - mse: 86.6351\n",
            "Epoch 21/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 86.6556 - mae: 6.8908 - mse: 86.6556\n",
            "Epoch 22/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6429 - mae: 6.8909 - mse: 86.6429\n",
            "Epoch 23/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6540 - mae: 6.8930 - mse: 86.6540\n",
            "Epoch 24/25\n",
            "2851/2851 [==============================] - 7s 2ms/step - loss: 86.6432 - mae: 6.8909 - mse: 86.6432\n",
            "Epoch 25/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 86.6473 - mae: 6.8921 - mse: 86.6473\n",
            "248/248 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenLayer1 (Dense)        (None, 8)                 128       \n",
            "                                                                 \n",
            " hiddenLayer2 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer3 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " hiddenLayer4 (Dense)        (None, 8)                 72        \n",
            "                                                                 \n",
            " outputLayer (Dense)         (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2851/2851 [==============================] - 6s 2ms/step - loss: 77.2462 - mae: 6.2062 - mse: 77.2462\n",
            "Epoch 2/25\n",
            "2851/2851 [==============================] - 5s 2ms/step - loss: 87.8246 - mae: 6.9514 - mse: 87.8246\n",
            "Epoch 3/25\n",
            "1619/2851 [================>.............] - ETA: 2s - loss: 87.9723 - mae: 6.9459 - mse: 87.9723"
          ]
        }
      ],
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def build_model(optimizer):#this functon just builds the architecture of our DNN\n",
        "  model = Sequential()\n",
        "  model.add(Input(\n",
        "      shape=(X_train.shape[1],)#(32,)\n",
        "      ,name='inputLayer'\n",
        "  ))\n",
        "  model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "                , kernel_initializer = 'uniform'\n",
        "                , activation = 'relu' \n",
        "                , name = 'hiddenLayer1'\n",
        "                )) \n",
        "  model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "                , kernel_initializer = 'uniform'\n",
        "                , activation = 'relu' \n",
        "                , name = 'hiddenLayer2'\n",
        "                )) \n",
        "  model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "                , kernel_initializer = 'uniform'\n",
        "                , activation = 'relu' \n",
        "                , name = 'hiddenLayer3'\n",
        "                ))\n",
        "  model.add(Dense(units = int(round((X_train.shape[1]+1)/2,0))\n",
        "                , kernel_initializer = 'uniform'\n",
        "                , activation = 'relu' \n",
        "                , name = 'hiddenLayer4'\n",
        "                ))\n",
        "  model.add(Dense(units = 1\n",
        "                , kernel_initializer = 'uniform' \n",
        "                , activation = 'linear' \n",
        "                , name = 'outputLayer'))\n",
        "  model.compile(\n",
        "      optimizer=optimizer\n",
        "      ,loss='mse'\n",
        "      ,metrics=['mae','mse']\n",
        "  )\n",
        "  model.summary()\n",
        "  #Fitting the MLP to the training set\n",
        "  return model\n",
        "model = KerasClassifier(build_fn=build_model)\n",
        "parameters = {'batch_size':[25,50]\n",
        "              ,'epochs':[25,75]\n",
        "              ,'optimizer':['adam','rmsprop','sgd']}\n",
        "grid_search = GridSearchCV(estimator = model\n",
        "                           ,param_grid = parameters\n",
        "                           ,scoring = 'neg_mean_squared_error'\n",
        "                           ,cv = 10)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_parameters = grid_search.best_params_\n",
        "best_mse = grid_search.best_score_\n",
        "print(best_parameters)\n",
        "print(best_mse)\n",
        "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)         \n",
        "# model_history = model.fit(X_train,y_train\n",
        "#           # ,batch_size=32\n",
        "#           # ,epochs=100\n",
        "#           ,validation_data = (X_test,y_test)\n",
        "#           ,callbacks=[early_stopping]\n",
        "#           ) #gonna tune both parameters\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}